{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x1 = 2*np.random.rand(100, 1)\n",
    "x2 = 2*np.random.rand(100, 1)\n",
    "x0 = np.array([1.0]) \n",
    "x0 = np.tile(x0, (100,1))\n",
    "X = np.concatenate((x1, x2), axis=1)\n",
    "\n",
    "X = np.concatenate((x0, X), axis=1)     # 100*3  2-d array(matrix)\n",
    "Y=3*x1+4*x2 +np.random.randn(100,1)+2   # 100*1  array \n",
    "#print(X)\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Normal Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.18659808]\n",
      " [2.78058884]\n",
      " [3.98352281]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import inv       # used to get inverse matrix\n",
    "XT = X.T\n",
    "#minW = np.dot(XT * X).I * XT * Y\n",
    "a = inv(np.dot(XT, X))\n",
    "b = np.dot(a, XT)\n",
    "minW = np.dot(b, Y)\n",
    "print(minW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Gradient Descent (Batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Square Error\n",
    "def MSE(w, x, y):    # x[i] and w are arrays, y[i] and mse are scalar\n",
    "    length = len(x)\n",
    "    MSE = 0.0\n",
    "    for i in range(0, length):\n",
    "        mse = (x[i]*w - y[i])**2\n",
    "        MSE += mse\n",
    "    MSE /= length\n",
    "    return MSE\n",
    "\n",
    "# Derivative of MSE to w\n",
    "def dMSE(w, x, y):\n",
    "    length = len(x)\n",
    "    sumdMSE = np.matrix('0.0, 0.0, 0.0')\n",
    "    for i in range(0, length):\n",
    "        deri = (np.dot(x[i],w) - y[i]) * x[i]\n",
    "        sumdMSE += deri\n",
    "    sumdMSE *= 2/length\n",
    "    return sumdMSE.T     # hrizontal [x1, x2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let learning rate = 1, because random data belongs [0, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.87436246]\n",
      " [14.3479013 ]\n",
      " [14.74575746]]\n",
      "[[1179.3519162]]\n"
     ]
    }
   ],
   "source": [
    "w = np.matrix('1.0;1.0;1.0')   # initialize, just give 1.0 \n",
    "step = 1    # learning rate\n",
    "\n",
    "oldMSE = 1000000              # a big number, just promise it bigger than the first MSE\n",
    "while MSE(w, X, Y) < oldMSE :\n",
    "    oldMSE = MSE(w, X, Y)\n",
    "    w = w - dMSE(w, X, Y) * step \n",
    "print(w)\n",
    "print(MSE(w, X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### According to the incredibly big MSE of rate = 1 , so changing it 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.18659834]\n",
      " [2.78058871]\n",
      " [3.9835227 ]]\n",
      "[[0.82383836]]\n"
     ]
    }
   ],
   "source": [
    "w = np.matrix('1.0;1.0;1.0')   # initialize, just give 1.0 \n",
    "step = 0.1\n",
    "\n",
    "oldMSE = 1000000\n",
    "while MSE(w, X, Y) < oldMSE :\n",
    "    oldMSE = MSE(w, X, Y)\n",
    "    w = w - dMSE(w, X, Y) * step \n",
    "print(w)\n",
    "print(MSE(w, X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Rate = 0.1 seems good, so I make it smaller to 0.01 in order to get more accurate coefficient  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.1865992 ]\n",
      " [2.78058828]\n",
      " [3.98352236]]\n",
      "[[0.82383836]]\n"
     ]
    }
   ],
   "source": [
    "# !!! This step may run for tens of seconds\n",
    "w = np.matrix('1.0;1.0;1.0')   #  initialize, just give 1.0 \n",
    "step = 0.01\n",
    "\n",
    "oldMSE = 1000000\n",
    "while MSE(w, X, Y) < oldMSE :\n",
    "    oldMSE = MSE(w, X, Y)\n",
    "    w = w - dMSE(w, X, Y) * step \n",
    "print(w)\n",
    "print(MSE(w, X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rate = 0.1 and Rate = 0.01 get almost the same result, which means rate = 0.1 has been small enough. As a result, test rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.93718123]\n",
      " [7.67395065]\n",
      " [7.87287873]]\n",
      "[[198.00315784]]\n"
     ]
    }
   ],
   "source": [
    "w = np.matrix('1.0;1.0;1.0')   #  initialize, just give 1.0 \n",
    "step = 0.5\n",
    "\n",
    "oldMSE = 1000000\n",
    "while MSE(w, X, Y) < oldMSE :\n",
    "    oldMSE = MSE(w, X, Y)\n",
    "    w = w - dMSE(w, X, Y) * step \n",
    "print(w)\n",
    "print(MSE(w, X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: learning rate = 0.1\n",
    "# Firstly, it contributes to a almost accurate result, which is almost the same to normal equation \n",
    "# Secondly, it runs very fast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
